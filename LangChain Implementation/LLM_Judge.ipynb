{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the Opik Library"
      ],
      "metadata": {
        "id": "N65gU-5wLUk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opik"
      ],
      "metadata": {
        "id": "oUY_7zNcLV-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Importing Necessary Libraries and Configuring Opik\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uSAtuK88C6Cq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8tRcLW60Rwi",
        "outputId": "97a56311-2ca2-4850-f5f2-546c4456b687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Your Opik API key is available in your account settings, can be found at https://www.comet.com/api/my/settings/ for Opik cloud\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Opik API key:··········\n",
            "Do you want to use \"rhythm\" workspace? (Y/n)y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ],
      "source": [
        "import opik\n",
        "from opik import Opik, track\n",
        "from opik.evaluation import evaluate\n",
        "from opik.evaluation.metrics import (Hallucination, AnswerRelevance)\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "opik.configure(use_local=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting the OpenAI API Key"
      ],
      "metadata": {
        "id": "F5o2MN2CFRJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "open_api_key = os.environ.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "eC46zsRx6fiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the CSV File into a DataFrame\n",
        "###In this cell, we load the CSV file into a pandas DataFrame. The CSV contains the query, LLM response, and retrieved passage, which will be used for evaluating the performance of the language model.\n",
        "\n"
      ],
      "metadata": {
        "id": "6-3sa8GTGUb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"Enter csv file path here\"\n",
        "df = pd.read_csv(file_path)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Gmw0KIx_14hL",
        "outputId": "6e1e5207-64b0-4994-82d4-a2c52dd4873d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2808121c7449>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Enter csv file path here\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating the LLM Responses\n",
        "In this cell, we process each row of the CSV file and evaluate the LLM response using the Hallucination and AnswerRelevance metrics. The results are saved in batches to avoid exceeding the rate limit, and progress is saved periodically."
      ],
      "metadata": {
        "id": "IqvKPRGuKdng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "results = []\n",
        "metrics = [Hallucination(), AnswerRelevance()]\n",
        "batch_size = 3  # Process in batches to reduce the chance of exceeding the rate limit\n",
        "\n",
        "for i in range(len(df)):\n",
        "    try:\n",
        "        row = df.iloc[i]\n",
        "        scores = {\"query\": row['Question'], \"answer\": row['Response']}\n",
        "\n",
        "        for metric in metrics:\n",
        "            try:\n",
        "                result = metric.score(\n",
        "                    input=row['Question'],\n",
        "                    output=row['Response'],\n",
        "                    context=row['passage'],\n",
        "                )\n",
        "                if isinstance(metric, Hallucination):\n",
        "                    scores[\"hallucination_score\"] = result.value\n",
        "                    scores[\"hallucination_reason\"] = result.reason\n",
        "                elif isinstance(metric, AnswerRelevance):\n",
        "                    scores[\"answer_relevance_score\"] = result.value\n",
        "                    scores[\"answer_relevance_reason\"] = result.reason\n",
        "            except Exception as e:\n",
        "                print(f\"Rate limit reached: {e}. Retrying in 15 seconds...\")\n",
        "                time.sleep(15)  # Wait and retry\n",
        "                continue\n",
        "\n",
        "        results.append(scores)\n",
        "\n",
        "        # Save progress every batch_size rows\n",
        "        if i % batch_size == 0:\n",
        "            pd.DataFrame(results).to_excel(\"intermediate_results.xlsx\", index=False)\n",
        "            print(f\"Progress saved at iteration {i}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at row {i}: {e}. Skipping to the next row...\")\n",
        "\n",
        "# Save final results\n",
        "result_df = pd.DataFrame(results)\n",
        "result_df.to_excel(\"final_results.xlsx\", index=False)\n",
        "print(\"Processing completed. Results saved to final_results.xlsx.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlYuVzb9-6Ud",
        "outputId": "eaa918e9-47cb-4d57-a382-ea4ca135d67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress saved at iteration 0\n",
            "Progress saved at iteration 3\n",
            "Progress saved at iteration 6\n",
            "Progress saved at iteration 9\n",
            "Progress saved at iteration 12\n",
            "Progress saved at iteration 15\n",
            "Progress saved at iteration 18\n",
            "Progress saved at iteration 21\n",
            "Progress saved at iteration 24\n",
            "Progress saved at iteration 27\n",
            "Processing completed. Results saved to final_results.xlsx.\n"
          ]
        }
      ]
    }
  ]
}